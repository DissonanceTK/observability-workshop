---
title: Setting up Zero configuration Auto instrumentation for APM
linkTitle: 30. Auto-instrumentation & APM
weight: 30
---

In the previous chapter, we enabled the OpenTelemetry Collector for Kubernetes on our cluster and configured it to send metrics both Kubernetes and Mysql metrics to the **Splunk Observability Cloud**. The next step is to enable auto-instrumentation for our Java apps running in the pods in our cluster.

{{% notice title="Zero Config Auto Instrumentation" style="info" %}}
It is important to understand that Zero Config Auto instrumentation is designed to get Trace/Span & Profiling data out of your existing application, without requiring  you to change your code or requiring to rebuild.
{{% /notice %}}

For this workshop we will be using the Zero config option of the Opentelemetry Collector in Kubernetes.
This means that the Collector monitors you pods running in Kubernetes, and if they match certain criteria, they will en able auto instrumentation on the pod.

For Java it is looking for the Kubernetes TAG `instrumentation.opentelemetry.io/inject-java\` set to `true`

## 1. Setting up Java auto instrumentation on the first pod

If you enable Zero configuration for a pod, the Collector will attach an initContainer to your existing pod, and restart the pod to activate it.

To show what happens when you enable Auto instrumentation, lets do a For & After of the content of a pod, the `api-gateway` in this case:

```bash
kubectl describe pods api-gateway |grep Image:
```

The resulting output should say:

```text
Image:         quay.io/phagen/spring-petclinic-api-gateway:0.0.2
```

This container is pulled from a remote repository `quay.io` and was not build to send traces to the **Splunk Observability Cloud**  

Lets enable the Java auto instrumentation on the api-gateway service first by adding the `inject-java` tag to kubernetes with the `kubectl patch deployment` command.
{{< tabs >}}
{{% tab title="Patch api-gateway service" %}}

```bash
kubectl patch deployment api-gateway -p '{"spec": {"template":{"metadata":{"annotations":{"instrumentation.opentelemetry.io/inject-java":"true"}}}} }'
```

{{% /tab %}}
{{% tab title="kubectl patch Output" %}}

```text
deployment.apps/api-gateway patched
```

{{% /tab %}}
{{< /tabs >}}

Lets recheck the container(s) in your pod for the after look:

```bash
kubectl describe pods api-gateway |grep Image:
```

Next to the original pod from before, you should see an initContainer named **opentelemetry-auto-instrumentation**. ( If you get two api-gateway containers, the original one is still terminating, so give ity a few seconds):

```text
Image:         ghcr.io/signalfx/splunk-otel-java/splunk-otel-java:v1.30.0
Image:         quay.io/phagen/spring-petclinic-api-gateway:0.0.2
```

## 2. Check the result in Splunk APM

Once the container is patched it will be restarted, let's go back to  the **Splunk Observability Cloud** with the URL provided by the Instructor to check our service.

First, Navigate to the **APM** ![APM](../images/apm-icon.png?classes=inline&height=25px) section to see the traces from your service in the **Explore** Pane. Use the filter option and change the *environment* filter **(1)** and search for the name of your workshop instance in the drop down box, it should be the [INSTANCE]-workshop. (where `INSTANCE` is the value from the shell script you run earlier). Make sure it is the only one selected.
![apm](../images/apm-api-gateway-overview.png)
You should see the name **(2)** of the service and metrics in the Latency and Request & Errors charts. (You can ignore the Critical Alert, Its caused by the sudden request increase generated by the load generator, It will become the norm in a bit and go away).

Next, click on **Explore** **(3)** to see the api-gateway service in the automatically generated dependency map and select the api-gateway service.
![apm map](../images/api-gateway-map.png)

## 3. Enable Java auto instrumentation on all pods

The above single service, will provide you *full fidelity* information on the interactions that are happening inside that one single service, something that can be useful, if you are 100% sure the issue you are trying to identify is only happening inside that specific service, independent of any relating services.

However, the more common scenario is that you need to see the full interaction  between all services. So lets patch all the deployments (labeled with `app.kubernetes.io/part-of=spring-petclinic`) to add the inject annotation.
remember: **This automatically causes pods to restart.**

Note, there will be no change for the *api-gateway* as we patched it earlier.

{{< tabs >}}
{{% tab title="Patch all Petclinic services" %}}

```bash
kubectl get deployments -l app.kubernetes.io/part-of=spring-petclinic -o name | xargs -I % kubectl patch % -p "{\"spec\": {\"template\":{\"metadata\":{\"annotations\":{\"instrumentation.opentelemetry.io/inject-java\":\"true\"}}}}}"

```

{{% /tab %}}
{{% tab title="kubectl patch Output" %}}

```text
deployment.apps/config-server patched
deployment.apps/admin-server patched
deployment.apps/customers-service patched
deployment.apps/visits-service patched
deployment.apps/discovery-server patched
deployment.apps/vets-service patched
deployment.apps/api-gateway patched (no change)
```

{{% /tab %}}
{{< /tabs >}}

It will take the Petclinic Microservice application a few minutes to start up and fully synchronise.
Lets monitor the  load generator container until its capable to generate load as show in the output tab.

{{< tabs >}}
{{% tab title="Tail Log" %}}

``` bash
. ~/workshop/petclinic/scripts/tail_logs.sh
```

{{% /tab %}}
{{% tab title="Tail Log Output" %}}

```text
{"severity":"info","msg":"Welcome Text = "Welcome to Petclinic"}
{"severity":"info","msg":"@ALL"
{"severity":"info","msg":"@owner details page"}
{"severity":"info","msg":"@pet details page"}
{"severity":"info","msg":"@add pet page"}
{"severity":"info","msg":"@veterinarians page"}
{"severity":"info","msg":"cookies was"}
```

{{% /tab %}}
{{< /tabs >}}

Once the services are fully initialized, you now should see all the different services appear in Splunk APM:
![all services](../images/apm-full-service.png)
Of course, we want to check the Dependency map by clicking Explore:
![full map](../images/apm-map-full.png)
