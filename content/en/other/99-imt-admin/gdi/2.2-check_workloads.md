---
title: Verifying OpenTelemetry Workload in the Splunk observability UI
linkTitle: 2.2 Verify OpenTelemetry Workload
weight: 2.2
time: 5 minutes
---

## 1. Examine the Kubernetes Navigator node view

![Filtered K8S node view](../images/k3s-node-view.png)

It will provide Node related info, like CPU and memory usage, Disk utilization, Log events and more. The node view will show you all the pods running on your node, and the number of containers running in each pod and their state.  
Take a minute to look at the various metrics and log generated by your node.

## 2. Verify the OpenTelemetry collectors workload

Verify the number of pods running in the Splunk UI by changing the view to **Kubernetes workloads** by selecting it in the *Entity* drop down **(1)**.  
You may need to reapply your filter by clicking on the {{% button %}}Add filters{{% /button %}} button **(2)**. Type in `k8s.cluster.name` and click on the search result.  
From the list, select **[NAME OF WORKSHOP]-k3s-cluster** then click on the {{% button style="blue" %}}Apply Filter{{% /button %}} button.
This should give you an overview of the workloads on your cluster.

![Workload cluster receiver](../images/k3s-otel-cluster-reciever.png)
test
![Workload Agent](../images/k3s-otel-agent.png)

Note the single container met de OpenTelemetry collector running in agent  mode **(3)** running per node among the default Kubernetes pods. This single container will monitor all the pods and services being deployed on this node!

Now switch back to the default cluster node view by selecting the **MAP** tab and selecting your cluster again.
